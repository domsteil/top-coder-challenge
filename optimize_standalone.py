#!/usr/bin/env python3
"""
Optimize standalone solutions that don't require external model files
Focus on improving decision tree and rule-based approaches
"""

import json
import numpy as np
from sklearn.tree import DecisionTreeRegressor
from decimal import Decimal as D

print("Loading public cases for analysis...")
with open('public_cases.json', 'r') as f:
    data = json.load(f)

# Analyze patterns in the data
print("\n" + "="*60)
print("PATTERN ANALYSIS")
print("="*60)

# Group cases by characteristics
patterns = {
    'very_low_receipts': [],  # < $50
    'low_receipts': [],       # $50-500
    'medium_receipts': [],    # $500-1500
    'high_receipts': [],      # > $1500
    'ends_49': [],
    'ends_99': [],
    'five_day_trips': [],
    'single_day_trips': [],
    'high_mileage': [],       # > 500 miles
    'efficiency_bonus': []    # 180-220 miles/day
}

for case in data:
    days = case['input']['trip_duration_days']
    miles = case['input']['miles_traveled']
    receipts = case['input']['total_receipts_amount']
    output = case['expected_output']
    
    receipt_str = f"{receipts:.2f}"
    miles_per_day = miles / days if days > 0 else miles
    
    # Categorize
    if receipts < 50:
        patterns['very_low_receipts'].append((days, miles, receipts, output))
    elif receipts < 500:
        patterns['low_receipts'].append((days, miles, receipts, output))
    elif receipts < 1500:
        patterns['medium_receipts'].append((days, miles, receipts, output))
    else:
        patterns['high_receipts'].append((days, miles, receipts, output))
    
    if receipt_str.endswith('49'):
        patterns['ends_49'].append((days, miles, receipts, output))
    elif receipt_str.endswith('99'):
        patterns['ends_99'].append((days, miles, receipts, output))
    
    if days == 5:
        patterns['five_day_trips'].append((days, miles, receipts, output))
    elif days == 1:
        patterns['single_day_trips'].append((days, miles, receipts, output))
    
    if miles > 500:
        patterns['high_mileage'].append((days, miles, receipts, output))
    
    if 180 <= miles_per_day <= 220:
        patterns['efficiency_bonus'].append((days, miles, receipts, output))

# Analyze each pattern
print("\nPattern Statistics:")
for pattern_name, cases in patterns.items():
    if cases:
        outputs = [c[3] for c in cases]
        avg_output = np.mean(outputs)
        
        # Calculate average reimbursement per day
        avg_per_day = np.mean([c[3] / c[0] for c in cases])
        
        # Calculate average reimbursement per mile
        avg_per_mile = np.mean([c[3] / c[1] if c[1] > 0 else 0 for c in cases])
        
        # Calculate receipt percentage
        avg_receipt_pct = np.mean([c[3] / c[2] if c[2] > 0 else 0 for c in cases])
        
        print(f"\n{pattern_name}: {len(cases)} cases")
        print(f"  Avg output: ${avg_output:.2f}")
        print(f"  Avg per day: ${avg_per_day:.2f}")
        print(f"  Avg per mile: ${avg_per_mile:.2f}")
        print(f"  Avg receipt %: {avg_receipt_pct:.2%}")

# Train a deeper decision tree
print("\n" + "="*60)
print("OPTIMIZED DECISION TREE")
print("="*60)

# Prepare features
X = []
y = []
for case in data:
    days = case['input']['trip_duration_days']
    miles = case['input']['miles_traveled']
    receipts = case['input']['total_receipts_amount']
    
    # Enhanced features for better tree splits
    miles_per_day = miles / days if days > 0 else miles
    receipts_per_day = receipts / days if days > 0 else receipts
    
    X.append([days, miles, receipts, miles_per_day, receipts_per_day])
    y.append(case['expected_output'])

X = np.array(X)
y = np.array(y)

# Try different tree depths
best_tree = None
best_mae = float('inf')
best_depth = None

for depth in range(5, 10):
    tree = DecisionTreeRegressor(max_depth=depth, min_samples_leaf=10, random_state=42)
    tree.fit(X, y)
    
    y_pred = tree.predict(X)
    mae = np.mean(np.abs(y - y_pred))
    
    print(f"Depth {depth}: MAE = ${mae:.2f}")
    
    if mae < best_mae:
        best_mae = mae
        best_tree = tree
        best_depth = depth

print(f"\nBest tree depth: {best_depth} with MAE ${best_mae:.2f}")

# Extract improved rules
print("\n" + "="*60)
print("EXTRACTING OPTIMIZED RULES")
print("="*60)

def extract_tree_rules(tree, feature_names):
    """Extract rules from decision tree in a format suitable for embedding"""
    tree_ = tree.tree_
    
    def recurse(node, depth=0, path=[]):
        if tree_.feature[node] == -2:  # Leaf node
            value = tree_.value[node][0][0]
            n_samples = tree_.n_node_samples[node]
            
            # Build condition string
            conditions = []
            for i, (feat_idx, threshold, direction) in enumerate(path):
                feat_name = feature_names[feat_idx]
                if direction == 'left':
                    conditions.append(f"{feat_name} <= {threshold:.2f}")
                else:
                    conditions.append(f"{feat_name} > {threshold:.2f}")
            
            return [(conditions, value, n_samples)]
        
        else:  # Decision node
            rules = []
            feat_idx = tree_.feature[node]
            threshold = tree_.threshold[node]
            
            # Left branch
            left_path = path + [(feat_idx, threshold, 'left')]
            rules.extend(recurse(tree_.children_left[node], depth + 1, left_path))
            
            # Right branch
            right_path = path + [(feat_idx, threshold, 'right')]
            rules.extend(recurse(tree_.children_right[node], depth + 1, right_path))
            
            return rules
    
    feature_names_list = ['days', 'miles', 'receipts', 'miles_per_day', 'receipts_per_day']
    rules = recurse(0)
    
    # Sort by number of samples (most common cases first)
    rules.sort(key=lambda x: x[2], reverse=True)
    
    return rules

rules = extract_tree_rules(best_tree, ['days', 'miles', 'receipts', 'miles_per_day', 'receipts_per_day'])

print(f"\nExtracted {len(rules)} rules from optimized tree")
print("\nTop 10 rules by frequency:")
for i, (conditions, value, samples) in enumerate(rules[:10]):
    print(f"\nRule {i+1} ({samples} samples, output=${value:.2f}):")
    for cond in conditions:
        print(f"  AND {cond}")

# Analyze residuals to find correction patterns
print("\n" + "="*60)
print("RESIDUAL ANALYSIS FOR CORRECTIONS")
print("="*60)

y_pred = best_tree.predict(X)
residuals = y - y_pred

# Find systematic patterns in residuals
receipt_endings = {'49': [], '99': [], 'other': []}
for i, case in enumerate(data):
    receipt_str = f"{case['input']['total_receipts_amount']:.2f}"
    if receipt_str.endswith('49'):
        receipt_endings['49'].append(residuals[i])
    elif receipt_str.endswith('99'):
        receipt_endings['99'].append(residuals[i])
    else:
        receipt_endings['other'].append(residuals[i])

print("\nAverage residuals by receipt ending:")
for ending, res_list in receipt_endings.items():
    if res_list:
        avg_residual = np.mean(res_list)
        print(f"  .{ending}: ${avg_residual:.2f} (n={len(res_list)})")

# Generate optimized standalone code
print("\n" + "="*60)
print("GENERATING OPTIMIZED STANDALONE CODE")
print("="*60)

# Convert tree to if-else statements
def generate_tree_code(tree, feature_names):
    """Generate Python code from decision tree"""
    tree_ = tree.tree_
    
    code_lines = []
    
    def recurse(node, depth=0):
        indent = "    " * depth
        
        if tree_.feature[node] == -2:  # Leaf
            value = tree_.value[node][0][0]
            code_lines.append(f"{indent}return D('{value:.2f}')")
        else:
            feat_idx = tree_.feature[node]
            threshold = tree_.threshold[node]
            feat_name = feature_names[feat_idx]
            
            code_lines.append(f"{indent}if {feat_name} <= {threshold:.2f}:")
            recurse(tree_.children_left[node], depth + 1)
            code_lines.append(f"{indent}else:  # {feat_name} > {threshold:.2f}")
            recurse(tree_.children_right[node], depth + 1)
    
    recurse(0)
    return '\n'.join(code_lines)

tree_code = generate_tree_code(best_tree, ['days', 'miles', 'receipts', 'miles_per_day', 'receipts_per_day'])

print("Generated decision tree code (first 20 lines):")
for line in tree_code.split('\n')[:20]:
    print(line)

print(f"\nâœ… Optimization complete!")
print(f"   Best standalone MAE: ${best_mae:.2f}")
print(f"   Expected score: {int(best_mae * 100)}")
print(f"   Improvement from current decision tree: {13161 - int(best_mae * 100)} points") 